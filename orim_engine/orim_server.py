#!/usr/bin/env python3
"""
ORIM Covert Channel Server (Final Edition)
Features:
- Protocol Framing (Magic + CID + CRC)
- Automatic Padding for Capacity Matching
- Bit-wise Sliding Window Decoding
- Debug Logging
"""

import zmq
import json
import hashlib
import hmac
import sqlite3
import sys
import os
import logging
from math import factorial
from typing import List, Tuple, Dict, Optional
from datetime import datetime

# === å¼•å…¥åè®®å°è£… ===
# ç›´æ¥ä» orim_engine åŒ…å¯¼å…¥
from protocol import ORIMProtocol

# é…ç½®æ—¥å¿— (è¿™æ˜¯ Server è¿è¡Œæ—¥å¿—)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('orim_server.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# ğŸ”¬ Debug Logger for Binary Tracing (Sender Side)
# ==========================================
debug_logger = logging.getLogger('sender_debug')
debug_logger.setLevel(logging.DEBUG)
# Calculate absolute path to storage directory
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
storage_dir = os.path.join(project_root, 'storage')
os.makedirs(storage_dir, exist_ok=True)
debug_log_path = os.path.join(storage_dir, 'sender_debug.log')

debug_handler = logging.FileHandler(debug_log_path, mode='a')
debug_handler.setLevel(logging.DEBUG)
debug_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
debug_logger.addHandler(debug_handler)
debug_logger.propagate = False

# Force immediate flush after each write
class FlushingHandler(logging.FileHandler):
    def emit(self, record):
        super().emit(record)
        self.flush()

# Replace with flushing handler
debug_logger.removeHandler(debug_handler)
debug_handler_flushing = FlushingHandler(debug_log_path, mode='a')
debug_handler_flushing.setLevel(logging.DEBUG)
debug_handler_flushing.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
debug_logger.addHandler(debug_handler_flushing)

logger.info(f"Debug logger initialized: {debug_log_path}")

class ORIMServer:
    def __init__(self, zmq_endpoint: str, prf_key: bytes, db_path: str):
        self.zmq_endpoint = zmq_endpoint
        self.prf_key = prf_key
        self.db_path = db_path
        
        # Init ZMQ
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.REP)
        self.socket.bind(zmq_endpoint)
        logger.info(f"ORIM Server listening on {zmq_endpoint}")
        
        self._init_database()
        
        # Stats
        self.stats = {'sent_msgs': 0, 'recv_msgs': 0, 'bits_sent': 0, 'bits_recv': 0}

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å‘é€é˜Ÿåˆ—
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS outgoing_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                message TEXT,
                bits TEXT,
                position INTEGER DEFAULT 0,
                completed_at TIMESTAMP NULL
            )
        ''')
        
        # æ¥æ”¶ç¼“å†²åŒº
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS incoming_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                peer_id INTEGER,
                bits TEXT,
                received_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # è§£ç ç»“æœ
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS decoded_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                message TEXT,
                decoded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()

    # ==========================================
    # æ ¸å¿ƒæ•°å­¦é€»è¾‘ (ORIM ç®—æ³•å®ç°)
    # ==========================================
    def prf(self, hash_hex: str) -> int:
        """PRF: Hash â†’ Integer (HMAC-SHA256 based)"""
        hash_bytes = bytes.fromhex(hash_hex)
        hmac_obj = hmac.new(self.prf_key, hash_bytes, hashlib.sha256)
        # Use full 256-bit output for better distribution
        return int.from_bytes(hmac_obj.digest(), byteorder='big')

    def compute_obfuscated_values(self, hashes: List[str]) -> List[int]:
        """Compute obfuscated values for all hashes using PRF (Algorithm 2, Step 1)"""
        obf_values = [self.prf(h) for h in hashes]
        debug_logger.debug(f"[PRF] Computed {len(obf_values)} obfuscated values")
        return obf_values

    def factorial_number_system(self, rank: int, n: int) -> List[int]:
        lehmer = []
        for i in range(n, 0, -1):
            fact = factorial(i - 1)
            lehmer.append(rank // fact)
            rank %= fact
        return lehmer

    def lehmer_to_permutation(self, lehmer: List[int]) -> List[int]:
        available = list(range(len(lehmer)))
        return [available.pop(c) for c in lehmer]

    def permutation_to_lehmer(self, permutation: List[int]) -> List[int]:
        n = len(permutation)
        lehmer = []
        for i in range(n):
            count = sum(1 for j in range(i + 1, n) if permutation[j] < permutation[i])
            lehmer.append(count)
        return lehmer

    def lehmer_to_rank(self, lehmer: List[int]) -> int:
        n = len(lehmer)
        return sum(c * factorial(n - 1 - i) for i, c in enumerate(lehmer))

    def bits_to_rank(self, bits: str, n: int) -> Tuple[int, int]:
        """
        Complete Binary Tree Variable-Length Encoding (Algorithm 2)
        
        Given n permutations (N = n!), encode bits to rank using:
        - Layer m (Long Code): m bits â†’ rank âˆˆ [0, T-1]
        - Layer m-1 (Short Code): m-1 bits â†’ rank âˆˆ [N - 2^(m-1), N-1]
        
        Where:
        - m: layer number such that 2^(m-1) â‰¤ N â‰¤ 2^m
        - T: threshold = 2N - 2^m (number of leaf nodes in layer m)
        
        Returns: (rank, consumed_bits)
        Guarantee: rank < N = n! (mathematically proven)
        """
        N = factorial(n)
        
        # Calculate layer m: 2^(m-1) â‰¤ N â‰¤ 2^m
        m = 1
        while (1 << m) < N:
            m += 1
        
        # Threshold T = 2N - 2^m
        T = 2 * N - (1 << m)
        
        # Special case: N is exactly a power of 2 (T = 0)
        if T == 0:
            # All codes use m bits
            if len(bits) < m:
                # Pad with zeros
                bits = bits.ljust(m, '0')
            val_m = int(bits[:m], 2)
            debug_logger.debug(f"[ENCODE] n={n} N={N} m={m} T={T} â†’ Layer-m (special): consumed={m} rank={val_m}")
            return val_m, m
        
        # General case: Complete Binary Tree
        # Peek at m bits to decide which layer
        if len(bits) >= m:
            val_m = int(bits[:m], 2)
            
            # Condition A: val_m < T â†’ use Layer m (Long Code)
            if val_m < T:
                debug_logger.debug(f"[ENCODE] n={n} N={N} m={m} T={T} â†’ Layer-m (long): val_m={val_m} consumed={m} rank={val_m}")
                return val_m, m
            
            # Condition B: val_m â‰¥ T â†’ use Layer m-1 (Short Code)
            else:
                val_m_minus_1 = int(bits[:m-1], 2)
                rank = N - (1 << (m - 1)) + val_m_minus_1
                debug_logger.debug(f"[ENCODE] n={n} N={N} m={m} T={T} â†’ Layer-m-1 (short): val_m={val_m}â‰¥T, val_{m-1}={val_m_minus_1} consumed={m-1} rank={rank}")
                return rank, m - 1
        
        elif len(bits) >= m - 1:
            # Only have m-1 bits, must use Layer m-1
            val_m_minus_1 = int(bits[:m-1], 2)
            rank = N - (1 << (m - 1)) + val_m_minus_1
            debug_logger.debug(f"[ENCODE] n={n} N={N} m={m} T={T} â†’ Layer-m-1 (forced): insufficient bits, val_{m-1}={val_m_minus_1} consumed={m-1} rank={rank}")
            return rank, m - 1
        
        else:
            # Insufficient bits even for m-1, pad and use Layer m-1
            bits_padded = bits.ljust(m - 1, '0')
            val_m_minus_1 = int(bits_padded, 2)
            rank = N - (1 << (m - 1)) + val_m_minus_1
            debug_logger.debug(f"[ENCODE] n={n} N={N} m={m} T={T} â†’ Layer-m-1 (padded): only {len(bits)} bits, padded val_{m-1}={val_m_minus_1} consumed={len(bits)} rank={rank}")
            return rank, len(bits)

    def rank_to_bits(self, rank: int, n: int) -> str:
        """
        Complete Binary Tree Variable-Length Decoding (Inverse of bits_to_rank)
        
        Decode rank to bits using the same layer logic:
        - If rank < T: decode as m-bit value
        - If rank â‰¥ N - 2^(m-1): decode as m-1-bit value from Layer m-1
        
        Returns: bits string (variable length)
        """
        N = factorial(n)
        
        # Calculate layer m
        m = 1
        while (1 << m) < N:
            m += 1
        
        # Threshold T = 2N - 2^m
        T = 2 * N - (1 << m)
        
        # Special case: N is exactly a power of 2
        if T == 0:
            bits = bin(rank)[2:].zfill(m)
            debug_logger.debug(f"[DECODE] n={n} rank={rank} â†’ Layer-m (special): {bits}")
            return bits
        
        # Determine which layer this rank belongs to
        layer_m_minus_1_start = N - (1 << (m - 1))
        
        if rank < T:
            # Layer m (Long Code): m bits
            bits = bin(rank)[2:].zfill(m)
            debug_logger.debug(f"[DECODE] n={n} rank={rank} < T={T} â†’ Layer-m: {bits}")
            return bits
        else:
            # Layer m-1 (Short Code): m-1 bits
            val_m_minus_1 = rank - layer_m_minus_1_start
            bits = bin(val_m_minus_1)[2:].zfill(m - 1)
            debug_logger.debug(f"[DECODE] n={n} rank={rank} â‰¥ {layer_m_minus_1_start} â†’ Layer-m-1: val={val_m_minus_1} bits={bits}")
            return bits

    # ==========================================
    # æ•°æ®æµå¤„ç†é€»è¾‘
    # ==========================================
    
    def get_next_secret_bits(self, n: int) -> Tuple[str, int, int, int]:
        """
        [Sender Logic] Fetch next bits from database with "Check & Consume" strategy
        
        Implements Algorithm 2 "Check & Consume" Step:
        1. Calculate N = n!, m, and threshold T
        2. Peek at next m bits from buffer
        3. Decide consumption:
           - If val_m < T: consume m bits (Layer m)
           - If val_m â‰¥ T: consume m-1 bits (Layer m-1)
        4. Calculate target_rank according to the layer
        
        Returns: (bits_chunk, msg_id, actual_data_len, target_rank)
        Guarantee: target_rank < N (no overflow possible)
        """
        N = factorial(n)
        
        # Calculate layer m: 2^(m-1) â‰¤ N â‰¤ 2^m
        m = 1
        while (1 << m) < N:
            m += 1
        
        # Threshold T = 2N - 2^m
        T = 2 * N - (1 << m)
        
        # Fetch message from database
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT id, bits, position FROM outgoing_messages WHERE completed_at IS NULL LIMIT 1')
        row = cursor.fetchone()
        
        if not row:
            conn.close()
            # No message to send, return dummy data
            dummy_bits = "0" * m
            debug_logger.info(f"[CHECK&CONSUME] n={n} N={N} m={m} T={T} â†’ No message, returning {m} dummy zeros")
            return (dummy_bits, -1, 0, 0)
        
        msg_id, full_bits, pos = row
        total_len = len(full_bits)
        remaining = total_len - pos
        
        # === "Check & Consume" Logic (Algorithm 2) ===
        
        # Special case: N is power of 2 (T = 0)
        if T == 0:
            # Always consume m bits
            chunk = full_bits[pos:pos + m]
            if len(chunk) < m:
                chunk = chunk.ljust(m, '0')  # Pad if insufficient
            target_rank = int(chunk, 2)
            actual_data_len = min(remaining, m)
            conn.close()
            debug_logger.info(f"[CHECK&CONSUME] n={n} N={N} m={m} T=0 (power-of-2) â†’ consumed={m} rank={target_rank}")
            return (chunk, msg_id, actual_data_len, target_rank)
        
        # General case: Check m bits to decide
        if remaining >= m:
            # Peek at m bits
            peek_m = full_bits[pos:pos + m]
            val_m = int(peek_m, 2)
            
            # Condition A: val_m < T â†’ use Layer m (Long Code)
            if val_m < T:
                chunk = peek_m
                consumed = m
                target_rank = val_m
                layer = f"Layer-m (long)"
            
            # Condition B: val_m â‰¥ T â†’ use Layer m-1 (Short Code)
            else:
                chunk = full_bits[pos:pos + m - 1]
                val_m_minus_1 = int(chunk, 2)
                consumed = m - 1
                target_rank = N - (1 << (m - 1)) + val_m_minus_1
                layer = f"Layer-m-1 (short)"
            
            actual_data_len = consumed
            conn.close()
            debug_logger.info(
                f"[CHECK&CONSUME] n={n} N={N} m={m} T={T} â†’ {layer}: "
                f"val_m={val_m if val_m < T else 'N/A'} consumed={consumed} rank={target_rank}"
            )
            return (chunk, msg_id, actual_data_len, target_rank)
        
        elif remaining >= m - 1:
            # Only have m-1 bits, must use Layer m-1
            chunk = full_bits[pos:pos + m - 1]
            val_m_minus_1 = int(chunk, 2)
            consumed = m - 1
            target_rank = N - (1 << (m - 1)) + val_m_minus_1
            actual_data_len = consumed
            conn.close()
            debug_logger.info(
                f"[CHECK&CONSUME] n={n} N={N} m={m} T={T} â†’ Layer-m-1 (forced, insufficient): "
                f"only {remaining} bits, consumed={consumed} rank={target_rank}"
            )
            return (chunk, msg_id, actual_data_len, target_rank)
        
        else:
            # Insufficient bits even for m-1, pad to m-1
            chunk = full_bits[pos:]
            chunk_padded = chunk.ljust(m - 1, '0')
            val_m_minus_1 = int(chunk_padded, 2)
            consumed = len(chunk)
            target_rank = N - (1 << (m - 1)) + val_m_minus_1
            actual_data_len = consumed
            conn.close()
            debug_logger.info(
                f"[CHECK&CONSUME] n={n} N={N} m={m} T={T} â†’ Layer-m-1 (padded): "
                f"only {remaining} bits, padded to {m-1}, consumed={consumed} rank={target_rank}"
            )
            return (chunk_padded, msg_id, actual_data_len, target_rank)

    def store_received_bits(self, peer_id: int, bits: str):
        """
        [æ¥æ”¶ç«¯é€»è¾‘] å­˜å…¥ç¼“å†²åŒºå¹¶å°è¯•è§£ç 
        åŒ…å«: è°ƒè¯•æ—¥å¿—å†™å…¥
        """
        # 1. å­˜å…¥æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        conn.execute('INSERT INTO incoming_messages (peer_id, bits) VALUES (?, ?)', (peer_id, bits))
        conn.commit()
        conn.close()
        
        # 2. [è°ƒè¯•] å†™å…¥ received_bits.log
        try:
            log_path = self.db_path.replace('orim.db', 'received_bits.log')
            with open(log_path, "a") as f:
                time_str = datetime.now().strftime("%H:%M:%S")
                f.write(f"[{time_str}] Len={len(bits)}: {bits}\n")
        except Exception as e:
            logger.error(f"Failed to write debug log: {e}")

        # 3. è§¦å‘è§£ç 
        # (å¦‚æœä½ ä»¥åå¯ç”¨äº†ç‹¬ç«‹çš„ decoder_service.pyï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™å°±è¡Œ)
        self._try_decode_messages()

    def _try_decode_messages(self):
        """
        [å†…éƒ¨è§£ç å™¨] å…¨é‡æ‰«æ + åè®®å±‚è¯†åˆ«
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # 1. æå–æ‰€æœ‰æ¯”ç‰¹æµæ‹¼æˆä¸€ä¸ªå¤§é•¿ä¸²
        cursor.execute('SELECT bits FROM incoming_messages ORDER BY received_at')
        rows = cursor.fetchall()
        full_stream = "".join([row[0] for row in rows])
        
        if not full_stream:
            conn.close()
            return

        # 2. å¾ªç¯è°ƒç”¨åè®®å±‚æ‰«æ
        while True:
            # ä½¿ç”¨å•æ¯”ç‰¹æ»‘åŠ¨çª—å£æ‰«æ (æ”¯æŒè‡ªåŠ¨å»Paddingï¼Œè‡ªåŠ¨çº é”™ä½)
            cid, bits_consumed = ORIMProtocol.decode_stream(full_stream)
            
            if cid:
                logger.info(f"ğŸ‰ DECODED FILE INDEX: {cid}")
                # å­˜å…¥è§£ç ç»“æœè¡¨
                cursor.execute('INSERT INTO decoded_messages (message) VALUES (?)', (cid,))
                conn.commit()
                
                # å‰ªæ‰å·²å¤„ç†çš„æ¯”ç‰¹
                full_stream = full_stream[bits_consumed:]
            else:
                # æ‰¾ä¸åˆ°äº†ï¼Œé€€å‡º
                break
        
        # 3. æ®‹ä½™å›æ”¶ (Residue Recycling)
        cursor.execute('DELETE FROM incoming_messages')
        
        # é™åˆ¶æ®‹æ¸£å¤§å°ï¼Œé˜²æ­¢æ— é™å¢é•¿
        if len(full_stream) > 4000:
            full_stream = full_stream[-4000:]
            
        if full_stream:
            # å°†å‰©ä¸‹çš„æ¯”ç‰¹å­˜å›å»ï¼Œä½œä¸ºä¸‹æ¬¡è§£ç çš„å¼€å¤´
            cursor.execute('INSERT INTO incoming_messages (peer_id, bits) VALUES (-1, ?)', (full_stream,))
            
        conn.commit()
        conn.close()

    # ==========================================
    # C++ äº¤äº’æ¥å£ (ZMQ Handlers)
    # ==========================================
    
    def handle_send_request(self, request: Dict) -> Dict:
        """å¤„ç†å‘é€è¯·æ±‚ï¼šå°†æ¯”ç‰¹ç¼–ç è¿›å“ˆå¸Œé¡ºåº"""
        try:
            hashes = request['hashes']
            n = len(hashes)
            if n < 2: return {'status': 'success', 'reordered_hashes': hashes}
            
            # 1. è®¡ç®—æ··æ·†å€¼å¹¶è·å–è‡ªç„¶åº
            obf_vals = self.compute_obfuscated_values(hashes)
            # è‡ªç„¶åº: æŒ‰ PRF å€¼ä»å°åˆ°å¤§çš„åŸå§‹ç´¢å¼•åˆ—è¡¨
            natural_order = [i for _, i in sorted((v, i) for i, v in enumerate(obf_vals))]
            
            # 2. è·å–æ¯”ç‰¹å¹¶è®¡ç®— target_rank (Algorithm 2: Check & Consume)
            # æ–°æ¥å£ç›´æ¥è¿”å› target_rankï¼Œä¿è¯ rank < n! (æ— éœ€å†æ¬¡éªŒè¯)
            bits, msg_id, actual_data_len, target_rank = self.get_next_secret_bits(n)
            
            # === FIX: å¦‚æœæ²¡æœ‰æ¶ˆæ¯è¦å‘é€ï¼ˆmsg_id=-1ï¼‰ï¼Œç›´æ¥è¿”å›åŸå§‹é¡ºåº ===
            if msg_id == -1:
                # æŒ‰è‡ªç„¶åºæ’åˆ—ï¼ˆPRFå€¼ä»å°åˆ°å¤§ï¼‰
                debug_logger.info(f"[SEND] n={n} No message \u2192 Natural order (rank=0)")
                return {'status': 'success', 'reordered_hashes': [hashes[i] for i in natural_order]}
            
            # 3. Log the encoding result
            # target_rank is already calculated by get_next_secret_bits using Algorithm 2
            # Mathematically guaranteed: target_rank < n! (no overflow possible)
            conn_read = sqlite3.connect(self.db_path)
            cursor_read = conn_read.cursor()
            cursor_read.execute('SELECT position FROM outgoing_messages WHERE id = ?', (msg_id,))
            current_pos = cursor_read.fetchone()[0]
            conn_read.close()
            
            # Calculate consumed bits by calling bits_to_rank again (for logging consistency)
            _, consumed = self.bits_to_rank(bits, n)
            
            debug_logger.debug(
                f"[SENDING_SLICE] MsgID={msg_id} Pos={current_pos} "
                f"BitsLen={len(bits)} ActualData={actual_data_len} Consumed={consumed} "
                f"Rank={target_rank} Bits={bits[:50]}{'...' if len(bits) > 50 else ''}"
            )
            
            # 4. æ›´æ–°æ•°æ®åº“å‘é€è¿›åº¦
            # ä½¿ç”¨ actual_data_len (å®é™…ä»æ•°æ®åº“æ¶ˆè€—çš„ä½æ•°)
            # è¿™ä¸ get_next_secret_bits è¿”å›çš„ consumed ä½æ•°ä¸€è‡´
            if msg_id != -1:
                with sqlite3.connect(self.db_path) as conn:
                    # Update position by actual consumed data length
                    conn.execute('UPDATE outgoing_messages SET position = position + ? WHERE id = ?', (actual_data_len, msg_id))
                    
                    # æ£€æŸ¥æ˜¯å¦å‘é€å®Œæ¯•
                    cursor = conn.execute('SELECT position, length(bits) FROM outgoing_messages WHERE id = ?', (msg_id,))
                    pos, total = cursor.fetchone()
                    if pos >= total:
                        conn.execute('UPDATE outgoing_messages SET completed_at = CURRENT_TIMESTAMP WHERE id = ?', (msg_id,))
                        logger.info(f"âœ… Message #{msg_id} transmission completed (Total bits: {total})")
            
            # 5. ç”Ÿæˆæ’åˆ—å¹¶é‡æ’å“ˆå¸Œ
            try:
                lehmer = self.factorial_number_system(target_rank, n)
                perm = self.lehmer_to_permutation(lehmer)
                final_indices = [natural_order[perm[i]] for i in range(n)]
            except Exception as e:
                logger.error(f"Permutation Error: n={n} rank={target_rank} error={e}")
                debug_logger.error(f"[PERM_ERROR] n={n} rank={target_rank} bits={bits} error={e}")
                # è¿”å›è‡ªç„¶åºä½œä¸ºå¤‡é€‰
                return {'status': 'success', 'reordered_hashes': [hashes[i] for i in natural_order]}
            
            self.stats['sent_msgs'] += 1
            self.stats['bits_sent'] += consumed
            logger.info(f"Sender: Encoded {consumed} bits (Rank={target_rank})")
            
            return {'status': 'success', 'reordered_hashes': [hashes[i] for i in final_indices]}
            
        except Exception as e:
            logger.error(f"Send Error: {e}")
            return {'status': 'error', 'message': str(e)}

    def handle_receive_request(self, request: Dict) -> Dict:
        """å¤„ç†æ¥æ”¶è¯·æ±‚ï¼šæ’åº -> æå–æ¯”ç‰¹"""
        try:
            hashes = request['hashes']
            n = len(hashes)
            
            # === CRITICAL FIX: Log single-hash trap ===
            if n < 2: 
                logger.info(f"Receiver: Ignored INV with {n} hash (need >= 2 for permutation)")
                return {'status': 'success'}
            # === End Fix ===
            
            # ... åé¢çš„ä»£ç ä¿æŒä¸å˜ ...
            
            # 1. é€†å‘è®¡ç®— Rank
            obf_vals = self.compute_obfuscated_values(hashes)
            
            # è¿˜åŸæ’åˆ—é€»è¾‘
            indexed_values = [(v, i) for i, v in enumerate(obf_vals)]
            sorted_indexed = sorted(indexed_values)
            sorted_order = [orig_idx for _, orig_idx in sorted_indexed]
            
            sorted_to_received = {s_idx: pos for pos, s_idx in enumerate(sorted_order)}
            rec_perm = [sorted_to_received[i] for i in range(n)]
            
            lehmer = self.permutation_to_lehmer(rec_perm)
            rank = self.lehmer_to_rank(lehmer)
            
            # 2. æå–æ¯”ç‰¹
            bits = self.rank_to_bits(rank, n)
            
            # ğŸ”¬ DEBUG: Log received bits
            debug_logger.debug(f"[RECEIVED_BITS] n={n} Rank={rank} ExtractedLen={len(bits)} Bits={bits}")
            
            # 3. å­˜å…¥å¹¶è§£ç 
            self.store_received_bits(request.get('peer_id', 0), bits)
            
            self.stats['recv_msgs'] += 1
            self.stats['bits_recv'] += len(bits)
            logger.info(f"Receiver: Extracted {len(bits)} bits (Rank={rank})")
            
            return {'status': 'success'}
            
        except Exception as e:
            logger.error(f"Recv Error: {e}")
            return {'status': 'error', 'message': str(e)}

    def run(self):
        logger.info("Service Loop Started.")
        while True:
            try:
                msg = self.socket.recv_string()
                req = json.loads(msg)
                resp = self.handle_send_request(req) if req['direction'] == 'send' else self.handle_receive_request(req)
                self.socket.send_string(json.dumps(resp))
            except KeyboardInterrupt:
                logger.info("Server Stopped.")
                break
            except Exception as e:
                logger.error(f"Loop Error: {e}")
                self.socket.send_string(json.dumps({'status': 'error'}))

# ==========================================
# å·¥å…·å‡½æ•°ï¼šæ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ— (CLIå…¥å£)
# ==========================================
def add_secret_message(db_path: str, cid_string: str):
    """
    å°† IPFS CID å°è£…ä¸ºåè®®å¸§å¹¶å­˜å…¥æ•°æ®åº“
    """
    try:
        # ä½¿ç”¨åè®®æ‰“åŒ… (Magic + CID + CRC)
        bits = ORIMProtocol.pack_cid(cid_string)
        
        # ğŸ”¬ TRACE STEP 1: Log full binary string after CID conversion
        debug_logger.debug(f"[NEW_MSG] CID={cid_string} TotalLen={len(bits)} Bits={bits}")
        
        conn = sqlite3.connect(db_path)
        conn.execute('INSERT INTO outgoing_messages (message, bits) VALUES (?, ?)', (cid_string, bits))
        msg_id = conn.execute('SELECT last_insert_rowid()').fetchone()[0]
        conn.commit()
        conn.close()
        
        # ğŸ”¬ TRACE STEP 2: Confirm database insertion
        debug_logger.debug(f"[DB_INSERTED] MsgID={msg_id} CID={cid_string} StoredBits={len(bits)}")
        
        print(f"âœ… Message Queued: {cid_string} (Encoded to {len(bits)} bits)")
    except ValueError as e:
        print(f"âŒ Error adding message: {e}")

if __name__ == '__main__':
    import argparse
    import os
    
    # 1. ç®—å‡ºç»å¯¹è·¯å¾„ (ä¸ç®¡ä½ åœ¨å“ªå¯åŠ¨ï¼Œè·¯å¾„æ°¸è¿œå›ºå®š)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # å‡è®¾ storage åœ¨ orim_server.py çš„ä¸Šä¸€çº§ç›®å½•çš„ storage æ–‡ä»¶å¤¹é‡Œ
    project_root = os.path.dirname(current_dir) 
    db_path_absolute = os.path.join(project_root, 'storage', 'orim.db')
    
    # æ‰“å°å‡ºæ¥æ£€æŸ¥
    print(f"ğŸ”§ [DEBUG] å¼ºåˆ¶æ•°æ®åº“ç»å¯¹è·¯å¾„: {db_path_absolute}")

    parser = argparse.ArgumentParser()
    # é‡ç‚¹ï¼šæŠŠé»˜è®¤å€¼æ”¹ä¸ºè¿™ä¸ªç»å¯¹è·¯å¾„å˜é‡
    parser.add_argument('--db', default=db_path_absolute, help='Path to SQLite database')
    parser.add_argument('--add-message', help='Add IPFS CID to queue')
    args = parser.parse_args()
    
    if args.add_message:
        add_secret_message(args.db, args.add_message)
    else:
        # å¯åŠ¨æ—¶ä½¿ç”¨ args.db
        ORIMServer('tcp://*:5555', b'secret', args.db).run()